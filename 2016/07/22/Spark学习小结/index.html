<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Spark学习小结 | wingOFeagle之技术博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="#什么是spark 

Spark是一种基于内存的分布式处理框架。其在hadoop MR基础上进行扩展，扩展后的spark不仅仅支持map与reduce的操作，而且支持包括map的Transform操作与包括reduce的Action操作。相较于受限于磁盘IO瓶颈的hadoop，基于内存的spark在性能的提升上有了较大的进步，尤其是以重复使用数据为主要特点的迭代运算（ML也上使用迭代运算）
官方">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark学习小结">
<meta property="og:url" content="http://yoursite.com/2016/07/22/Spark学习小结/index.html">
<meta property="og:site_name" content="wingOFeagle之技术博客">
<meta property="og:description" content="#什么是spark 

Spark是一种基于内存的分布式处理框架。其在hadoop MR基础上进行扩展，扩展后的spark不仅仅支持map与reduce的操作，而且支持包括map的Transform操作与包括reduce的Action操作。相较于受限于磁盘IO瓶颈的hadoop，基于内存的spark在性能的提升上有了较大的进步，尤其是以重复使用数据为主要特点的迭代运算（ML也上使用迭代运算）
官方">
<meta property="og:updated_time" content="2016-07-22T10:02:51.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark学习小结">
<meta name="twitter:description" content="#什么是spark 

Spark是一种基于内存的分布式处理框架。其在hadoop MR基础上进行扩展，扩展后的spark不仅仅支持map与reduce的操作，而且支持包括map的Transform操作与包括reduce的Action操作。相较于受限于磁盘IO瓶颈的hadoop，基于内存的spark在性能的提升上有了较大的进步，尤其是以重复使用数据为主要特点的迭代运算（ML也上使用迭代运算）
官方">
  
    <link rel="alternate" href="/atom.xml" title="wingOFeagle之技术博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">wingOFeagle之技术博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">一步步，一点点...</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Spark学习小结" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/22/Spark学习小结/" class="article-date">
  <time datetime="2016-07-22T10:02:21.000Z" itemprop="datePublished">2016-07-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Spark学习小结
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>#什么是spark </p>
<ul>
<li><strong>Spark</strong>是一种基于内存的分布式处理框架。其在hadoop MR基础上进行扩展，扩展后的spark不仅仅支持map与reduce的操作，而且支持包括map的Transform操作与包括reduce的Action操作。相较于受限于磁盘IO瓶颈的hadoop，基于内存的spark在性能的提升上有了较大的进步，尤其是以重复使用数据为主要特点的迭代运算（ML也上使用迭代运算）<ul>
<li>官方主页：<a href="http://spark.apache.org/docs/latest/" target="_blank" rel="external">http://spark.apache.org/docs/latest/</a></li>
</ul>
</li>
<li><strong>spark 运行模式</strong><ul>
<li>本地模式</li>
<li>Standalone模式</li>
<li>Mesoes模式</li>
<li>yarn模式</li>
</ul>
</li>
<li><strong>spark 配置</strong><ul>
<li><a href="http://spark.apache.org/docs/latest/configuration.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/configuration.html</a></li>
</ul>
</li>
<li><p><strong>spark常用名词</strong></p>
<ul>
<li><strong>master &amp; worker</strong>，整个集群分为 Master 节点和 Worker 节点，相当于 Hadoop 的 Master 和 Slave 节点</li>
<li><strong>Master</strong> 节点上常驻 Master 守护进程，负责管理全部的 Worker 节点</li>
<li><strong>Worker</strong> 节点上常驻 Worker 守护进程，负责与 Master 节点通信并管理 executors</li>
<li><strong>driver application</strong>，即要运行的spark程序</li>
<li><strong>executor</strong>，在一个Worker Node上为应用启动的工作进程，在进程中赋值任务的运行，并且负责将数据存放在内存或磁盘上，必须注意的是，每个应用在一个Worker Node上只会有一个Executor，在Executor内部通过多线程的方式并发处理应用的任务</li>
<li><strong>job</strong>，和Spark的action相对应，每一个action例如count、saveAsTextFile等都会对应一个job实例，该job实例包含多任务的并行计算<br>cluster manager，集群资源的管理外部服务，在spark上现在有standalone、yarn、mesos等三种集群资源管理器，spark自带的standalone模式能够满足大部分的spark计算环境对集群资源管理的需求，基本上只有在集群中运行多套计算框架的时候才考虑yarn和mesos</li>
<li><strong>task</strong></li>
<li><a href="&quot;/img/RDD1.png&quot;">RDD1</a></li>
<li><strong>RDD</strong>，即resilient distributed dataset，弹性分布式数据集。它是一个只读，可分区的分布式数据集，这些数据集大部分分布在内存中（当然可以控制存储级别：内存、磁盘等）。RDD的初始化通过sparkcontext进行加载，加载的来源既可以是以hdfs为代表的分布式存储系统也可以是普通的文件。针对RDD的数据集，spark提供了两类操作，transform（返回值还是一个RDD）与action（返回值不是一个RDD）<ul>
<li>Transformations (如：map, filter, groupBy, join等)，Transformations操作是Lazy的，也就是说从一个RDD转换生成另一个RDD的操作不是马上执行，Spark在遇到Transformations操作时只会记录需要这样的操作，并不会去执行，需要等到有Actions操作的时候才会真正启动计算过程进行计算</li>
<li>Actions)（如：count, collect, save等)，Actions操作会返回结果或把RDD数据写到存储系统中。Actions是触发Spark启动计算的动因。</li>
<li>如下图所示，RDD的存储结构。事实上，每个RDD的数据都以Block的形式存储于多台机器上，其中每个Executor会启动一个BlockManagerSlave，并管理一部分Block；而Block的元数据由Driver节点的BlockManagerMaster保存。BlockManagerSlave生成Block后向BlockManagerMaster注册该Block，BlockManagerMaster管理RDD与Block的关系，当RDD不再需要存储的时候，将向BlockManagerSlave发送指令删除相应的Block。<br><a href="&quot;/img/RDD2.png&quot;">RDD2</a></li>
<li>Reference：</li>
<li><pre><code>RDD 原理： http://blog.csdn.net/stark_summer/article/details/47174733；
RDD: http://www.aboutyun.com/forum.php?mod=viewthread&amp;tid=7214&amp;page=1
Spark：http://tech.uc.cn/?p=2116
spark名词解释：http://blog.csdn.net/stark_summer/article/details/42833609
</code></pre></li>
</ul>
</li>
<li><strong>DAG</strong>：Direct Acycle graph，有向无环图，反映RDD之间的依赖关系</li>
<li><strong>narrow dependency</strong>，子RDD 依赖于父RDD 固定的data partition</li>
<li><p><strong>wide/shuffle dependency</strong>，子RDD 依赖于父RDD 所有的data partition</p>
<h1 id="spark的应用场景"><a href="#spark的应用场景" class="headerlink" title="spark的应用场景"></a>spark的应用场景</h1><p>spark可以用于实时计算（需要较高的内存要求，更加适合于迭代或者重复运算）、ML、关系数据查询、图形处理<br><a href="&quot;/img/spark应用.png&quot;">spark应用</a></p>
<pre><code>.
</code></pre><h1 id="spark的容错机制"><a href="#spark的容错机制" class="headerlink" title="spark的容错机制"></a>spark的容错机制</h1></li>
</ul>
</li>
<li>基于RDD 的分布式spark容错机制<strong>Lineage</strong>，其具有两种方式分别是数据检查点和记录数据的更新<ul>
<li>数据检查点是在某个stage将结果存储下来，当失败的节点恢复后节点从文件中读取数据进行加载恢复业务，优点是能够较快的恢复数据，缺点是会生成大量的数据文件<ul>
<li>Reference：<a href="http://www.cnblogs.com/gaoxing/p/4847119.html" target="_blank" rel="external">http://www.cnblogs.com/gaoxing/p/4847119.html</a></li>
</ul>
</li>
<li>记录数据的更新，它是把RDD生成的依赖关系记录下来，当数据丢失时根据依赖关系重新生成数据。当前RDD只支持粗粒度转换（细粒度的成本更新成本太高），即只记录单个块上执行的单个操作，然后将创建RDD的一系列变换序列（每个RDD都包含了他是如何由其他RDD变换过来的以及如何重建某一块数据的信息。因此RDD的容错机制又称“血统(Lineage)”容错）记录下来，以便恢复丢失的分区。其优点是对于窄依赖（narrow dependency）可以很快的进行数据还原，但对于复杂且Lineage较长的宽依赖则耗时较长而且往往占用较多的资源，因此在处理Lineage较长的宽依赖时往往采用“数据检查点+记录数据更新”的方式。<ul>
<li>Reference：<a href="http://www.jianshu.com/p/99ebcc7c92d3" target="_blank" rel="external">http://www.jianshu.com/p/99ebcc7c92d3</a><h1 id="spark-的资源管理与任务调度"><a href="#spark-的资源管理与任务调度" class="headerlink" title="spark 的资源管理与任务调度"></a>spark 的资源管理与任务调度</h1></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>##资源管理</p>
<ul>
<li>spark的资源管理一般由cluster manager进行</li>
<li>不同application间，支持资源动态调整，设定时间内无活动的job所占用的资源会被回收，需要资源的job spark会以1-2-4-8以此类推的形式逐步分配资源</li>
<li>同一个application内，不同的线程可以组成不同的池（pool），池可以设置不同的优先级来将资源优先分配给更重要job。缺省配置下，不同的池采用Roundrobin进行资源调度，同一个池内job采用FIFO进行调度</li>
<li><p>Reference：官网资源调度说明，<a href="http://spark.apache.org/docs/latest/job-scheduling.html#graceful-decommission-of-executors" target="_blank" rel="external">http://spark.apache.org/docs/latest/job-scheduling.html#graceful-decommission-of-executors</a></p>
<h2 id="任务调度"><a href="#任务调度" class="headerlink" title="任务调度"></a>任务调度</h2><p><a href="&quot;/img/spark 调度1.png&quot;">spark 调度1</a><br><a href="&quot;/img/spark 调度2.png&quot;">spark 调度2</a><br><a href="&quot;/img/spark 调度3.png&quot;">spark 调度3</a></p>
<p> 在用户创建 SparkContext 对象时，Spark会在内部创建 DAGScheduler 对象，并根据用户的部署情况，绑定不同的 TaskSechduler ，并启动DAGScheduler。基于生产-消费模型的DAGSchedual启动后调用 processEvent来处理block queue 中的event（event类型：JobSubmitted/CompletionEvent/ExecutorLost/TaskFailed/StopDAGScheduler），其具体的流程如下：</p>
</li>
</ul>
<ol>
<li>客户端启动Driver（spark作业的master）时同时启动JobGenerator，其根据Dstream的关系生成逻辑RDD，并创建Jobset；</li>
<li>用户提交的Job时（JobSchedual负责调度Jobset，即Job集合），对应的action操作触发sparkcontext调用RunJob函数，该函数执行DAGSchedualer的RunJob函数，而该函数把job封装成JobSubmitted 事件后放入block queue，等待执行；</li>
<li><p>DAGSchedual的daemon线程调用processEvent函数 从 block queue中取出 JobSubmitted事件后，根据job划分成不同的stage，然后根据每个stage产生task；</p>
<pre><code>1） 根据stage所依赖的 RDD 的partition的分布，会产生出与partition数量相等的task，这些task根据partition的locality进行分布；
2） 对于 finalStage 或是mapStage 会产生不同的task；
3） 所有的task会封装到 TaskSet 类内进行处理；
</code></pre></li>
<li>这些TaskSet类由TaskSetManager来进行管理（包括task的运行状态，locality处理，比如需要delay scheduling）；</li>
<li>那么，TaskSetManager是怎么管理这些task的呢？原来它会调用其内的resourceOffer方法，该方法实现task与底下资源的交互，这个资源交互的协调人是TaskScheduler；</li>
<li>同时，TaskScheduler对接不同的SchedulerBackend的实现(比如mesos，yarn，standalone)，如此来对接不同的资源管理系统 ；</li>
<li>而对资源管理系统来说，他们要负责的是进程，是worker上起几个executor进程，每个进程分配多少资源。所以这两层很清楚， spark本身计算框架内管理线程级别的task ，每个stage都有一个TaskSet，本身是个小DAG，可以丢到全局可用的资源池里跑；spark下半身的 双层资源管理部分掌控的是进程级别的executor ，不关心task怎么摆放，也不关心task运行状态，这是TaskSetManager管理的事情， 两者的协调者就是TaskScheduler及其内的SchedulerBackend实现（即将线程级别的task调度到进程级别的executor上）。</li>
</ol>
<ul>
<li>Reference：<ul>
<li>spark streaming 原理：<a href="http://blog.csdn.net/stark_summer/article/details/47252619" target="_blank" rel="external">http://blog.csdn.net/stark_summer/article/details/47252619</a></li>
<li>spark 任务调度：<a href="http://www.aboutyun.com/thread-8548-1-1.html" target="_blank" rel="external">http://www.aboutyun.com/thread-8548-1-1.html</a></li>
<li>spark任务调度：<a href="http://www.tuicool.com/articles/IZr6bi" target="_blank" rel="external">http://www.tuicool.com/articles/IZr6bi</a></li>
<li>spark总况：<a href="http://blog.csdn.net/stark_summer/article/details/45917603" target="_blank" rel="external">http://blog.csdn.net/stark_summer/article/details/45917603</a><h1 id="spark扩容"><a href="#spark扩容" class="headerlink" title="spark扩容"></a>spark扩容</h1></li>
</ul>
</li>
<li><strong>动态扩容</strong>：<a href="http://blog.csdn.net/rosen_luo/article/details/46738165" target="_blank" rel="external">http://blog.csdn.net/rosen_luo/article/details/46738165</a></li>
<li><strong>非动态扩容</strong>：<a href="http://www.linuxidc.com/Linux/2015-08/120937.htm" target="_blank" rel="external">http://www.linuxidc.com/Linux/2015-08/120937.htm</a><h1 id="spark的组件"><a href="#spark的组件" class="headerlink" title="spark的组件"></a>spark的组件</h1></li>
<li><strong>akka</strong>，消息队列系统，在spark中作为消息系统为master,worker,driver等通信 <ul>
<li>Reference<ul>
<li>akka：<a href="http://zuohongbin.com/2014/12/16/Akka-Tutorial-with-Code-Conncurrency-and-Fault-Tolerance/" target="_blank" rel="external">http://zuohongbin.com/2014/12/16/Akka-Tutorial-with-Code-Conncurrency-and-Fault-Tolerance/</a></li>
<li>spark总况：<a href="http://blog.csdn.net/stark_summer/article/details/45917603" target="_blank" rel="external">http://blog.csdn.net/stark_summer/article/details/45917603</a></li>
</ul>
</li>
</ul>
</li>
<li><strong>tachyon</strong>，分布式内存文件系统，在spark中用来存储RDD<ul>
<li>Reference：<ul>
<li>tachyon：<a href="http://www.csdn.net/article/2015-06-25/2825056" target="_blank" rel="external">http://www.csdn.net/article/2015-06-25/2825056</a></li>
<li>spark总况：<a href="http://blog.csdn.net/stark_summer/article/details/45917603" target="_blank" rel="external">http://blog.csdn.net/stark_summer/article/details/45917603</a></li>
</ul>
</li>
</ul>
</li>
<li><strong>netty</strong>，一个基于事件驱动的网络通信框架，目前在spark中主要作为spark shuffle处理后 从各个解决拉取shuffle数据（shuffle dependency阶段使用）<ul>
<li>Reference：<ul>
<li>spark总况：<a href="http://blog.csdn.net/stark_summer/article/details/45917603" target="_blank" rel="external">http://blog.csdn.net/stark_summer/article/details/45917603</a></li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/22/Spark学习小结/" data-id="ciqxkwbel000056j6k0pksez9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2016/07/22/test/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">test</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/">Spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/test/">test</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/test/">test</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Spark/" style="font-size: 20px;">Spark</a> <a href="/tags/test/" style="font-size: 10px;">test</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/07/22/Spark学习小结/">Spark学习小结</a>
          </li>
        
          <li>
            <a href="/2016/07/22/test/">test</a>
          </li>
        
          <li>
            <a href="/2016/07/20/spark安装/">Centos下Spark的安装</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Gason<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>