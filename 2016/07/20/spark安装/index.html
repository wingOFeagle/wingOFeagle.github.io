

<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <script type="text/javascript" src="http://tajs.qq.com/stats?sId=44218032" charset="UTF-8"></script>
  <script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?7192fa361f5cabb11d8a22de41c1ba8f";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>
  
  <title>Centos下Spark的安装 | wingOFeagle之技术博客</title>
  <meta name="author" content="Gason">
  
  <meta name="description" content="ok">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Centos下Spark的安装"/>
  <meta property="og:site_name" content="wingOFeagle之技术博客"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/imgs/favicon.ico" rel="icon" type="image/x-ico">
  <link rel="alternate" href="/atom.xml" title="wingOFeagle之技术博客" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <script src="//libs.baidu.com/jquery/1.8.0/jquery.min.js"></script>
</head>


<body>
  <header><div>
		
			<div id="imglogo">
				<a href="/"><img src="/imgs/logo.png" alt="wingOFeagle之技术博客" title="wingOFeagle之技术博客"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name">wingOFeagle之技术博客</h1>
				<h2 class="blog-motto">一步步，一点点...</h2>
			</div>
			<nav class="animated">
				<ul>
					
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li> <a href="/atom.xml">RSS</a> </li>
				</ul>
			</nav>			
</div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header class="article-info clearfix">
  <h1 itemprop="name">
	Centos下Spark的安装
  </h1>
  <p class="article-author">By
    
      <a href="http://yoursite.com" title="Gason">Gason</a>
    </p>
  <p class="article-time">
    <time datetime="2016-07-20T12:48:32.000Z" itemprop="datePublished">2016-07-20</time>
    Update date:<time datetime="2016-07-22T08:06:48.000Z" itemprop="dateModified">2016-07-22</time>
    
  </p>
</header>
    <div class="entry">
		
        <p>#Centos下Spark的安装与配置</p>
<p>##安装JDK</p>
<p>安装JDK大致分为下面4个步骤<br>用户可以在Oracle JDK的官网下载相应版本的JDK，本例以JDK 1.6为例，官网地址为<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="external">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a></p>
<ul>
<li><p>下载后，在解压出的JDK的目录下执行bin文件</p>
<pre><code>./jdk-6u38-ea-bin-b04-linux-amd64-31_oct_2012.bin
</code></pre></li>
<li><p>配置环境变量，在/etc/profile增加以下代码</p>
<pre><code>JAVA_HOME=/home/chengxu/jdk1.6.0_38 
PATH=$JAVA_HOME/bin:$PATH 
CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/jre/lib/dt.jar:$JAVA_HOME/jre/lib/tools.jar 
export JAVA_HOME PATH CLASSPATH
</code></pre></li>
<li><p>使profile文件更新生效</p>
</li>
<li><pre><code>./etc/profile
</code></pre><p>##安装Scala<br>Scala官网提供各个版本的Scala，用户需要根据Spark官方规定的Scala版本进行下载和安装。Scala官网地址为<a href="http://www.scala-lang.org/.以Scala-2.10为例进行介绍" target="_blank" rel="external">http://www.scala-lang.org/.以Scala-2.10为例进行介绍</a>.</p>
</li>
<li><p>下载scala-2.10.4.tgz</p>
</li>
<li>在目录下解压：tar -xzvf scala-2.10.4.tgz</li>
<li>配置环境变量，在/etc/profile中添加下面的内容</li>
<li><pre><code>export SCALA_HOME=/home/chengxu/scala-2.10.4/scala-2.10.4 
export PATH=${SCALA_HOME}/bin:$PATH
</code></pre></li>
<li>使profile文件更新生效</li>
<li><pre><code>./etc/profile
</code></pre><p>##配置SSH免密码登录</p>
<blockquote>
<p> 在集群管理和配置中有很多工具可以使用。例如，可以采用pssh等Linux工具在集群中分发与复制文件，用户也可以自己书写Shell、Python的脚本分发包。Spark的Master节点向Worker节点发命令需要通过ssh进行发送，用户不希望Master每发送一次命令就输入一次密码，因此需要实现Master无密码登录到所有Worker。<br>Master作为客户端，要实现无密码公钥认证，连接到服务端Worker。需要在Master上生成一个密钥对，包括一个公钥和一个私钥，然后将公钥复制到Worker上。当Master通过ssh连接Woker时，Worker就会生成一个随机数并用Master的公钥对随机数进行加密，发送给Worker。Master收到加密数之后再用私钥进行解密，并将解密数回传给Worker，Worker确认解密数无误之后，允许Master进行连接。这就是一个公钥认证过程，其间不需要用户手工输入密码，主要过程是将Master节点公钥复制到Worker节点上。<br>下面介绍如何配置Master与Worker之间的SSH免密码登录。</p>
</blockquote>
</li>
<li><p>在Master节点上，执行以下命令</p>
</li>
<li><pre><code>ssh-keygen -t rsa
</code></pre></li>
<li>打印日志执行以下命令</li>
<li><pre><code>Generating public/private rsa key pair. 
Enter file in which to save the key (/root/.ssh/id_rsa): 
/*回车，设置默认路径*/ 
Enter passphrase (empty for no passphrase): 
/*回车，设置空密码*/ 
Enter same passphrase again: 
Your identification has been saved in /root/.ssh/id_rsa. 
Your public key has been saved in /root/.ssh/id_rsa.pub.
如果是root用户，则在/root/.ssh/目录下生成一个私钥id_rsa和一个公钥id_rsa.pub。
 把Master上的id_rsa.pub文件追加到Worker的authorized_keys内，以172.20.14.144 （Worker）节点为例
</code></pre></li>
<li><p>复制Master的id_rsa.pub文件</p>
</li>
<li><pre><code>scp id_rsa.pub root@172.20.14.144:/home
</code></pre></li>
<li>可使用pssh对全部节点分发</li>
<li><pre><code>登录172.20.14.144 (Worker节点)，执行以下命令。
cat /home/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys 
/*可使用pssh对全部节点分发*/
</code></pre>其他的Worker执行同样的操作。</li>
</ul>
<blockquote>
<p>注意：配置完毕，如果Master仍然不能访问Worker，可以修改Worker的authorized_keys文件的权限，命令为chmod 600 authorized_keys。</p>
</blockquote>
<p>##安装Hadoop</p>
<p>下面讲解Hadoop的安装过程和步骤。</p>
<p>###1.下载hadoop-2.2.0</p>
<ul>
<li>选取一个Hadoop镜像网址，下载Hadoop（官网地址为<a href="http://hadoop.apache.org/）" target="_blank" rel="external">http://hadoop.apache.org/）</a></li>
<li><pre><code>$ wget http://www.trieuvan.com/apache/hadoop/common/ hadoop-2.2.0/hadoop-2.2.0.tar.gz
</code></pre></li>
<li>解压tar包</li>
<li><pre><code>$ sudo tar-vxzf hadoop-2.2.0.tar.gz -C /usr/local 
$ cd /usr/local 
$ sudo mv hadoop-2.2.0 hadoop 
$ sudo chown -R hduser:hadoop hadoop
</code></pre><p>###2. 配置Hadoop环境变量</p>
<ul>
<li>编辑profile文件</li>
<li><pre><code>vi /etc/profile
</code></pre></li>
<li><p>在profile文件中增加以下内容</p>
</li>
<li><pre><code>export JAVA_HOME=/usr/lib/jvm/jdk/ 
export HADOOP_INSTALL=/usr/local/hadoop 
export PATH=$PATH:$HADOOP_INSTALL/bin 
export PATH=$PATH:$HADOOP_INSTALL/sbin 
export HADOOP_MAPRED_HOME=$HADOOP_INSTALL 
export HADOOP_COMMON_HOME=$HADOOP_INSTALL 
export HADOOP_HDFS_HOME=$HADOOP_INSTALL 
export YARN_HOME=$HADOOP_INSTALL
</code></pre>通过如上配置就可以让系统找到JDK和Hadoop的安装路径。</li>
</ul>
</li>
</ul>
<p>###3. 编辑配置文件</p>
<ul>
<li><p>进入Hadoop所在目录/usr/local/hadoop/etc/hadoop</p>
</li>
<li><p>配置hadoop-env.sh文件</p>
</li>
<li><pre><code>export JAVA_HOME=/usr/lib/jvm/jdk/
</code></pre></li>
<li>配置core-site.xml文件（主配置文件）</li>
<li><pre><code>&lt;configuration&gt;
/*这里的值指的是默认的HDFS路径*/ 
&lt;property&gt;
&lt;name&gt;fs.defaultFS&lt;/name&gt;
&lt;value&gt;hdfs://Master:9000&lt;/value&gt;
&lt;/property&gt;
/*缓冲区大小:io.file.buffer.size默认是4KB*/ 
&lt;property&gt;
&lt;name&gt;io.file.buffer.size&lt;/name&gt;
&lt;value&gt;131072&lt;/value&gt;
&lt;/property&gt;
/*临时文件夹路径*/ 
&lt;property&gt;
&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
&lt;value&gt;file:/home//tmp&lt;/value&gt;
&lt;description&gt;Abase for other  
temporary directories.       &lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;hadoop.proxyuser.hduser.hosts&lt;/name&gt;
&lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;hadoop.proxyuser.hduser.groups&lt;/name&gt;
&lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
<li>配置yarn-site.xml文件（资源调度文件）</li>
<li><pre><code>&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
&lt;/property&gt;
/*resourcemanager的地址*/ 
&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
&lt;value&gt;Master:8032&lt;/value&gt;
&lt;/property&gt;
/*调度器的端口*/ 
&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
&lt;value&gt; Master1:8030&lt;/value&gt;
&lt;/property&gt;
/*resource-tracker端口*/ 
&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
&lt;value&gt; Master:8031&lt;/value&gt;
&lt;/property&gt;
/*resourcemanager管理器端口*/ 
&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
&lt;value&gt; Master:8033&lt;/value&gt;
&lt;/property&gt;
/* ResourceManager 的 Web 端口，监控 job 的资源调度*/ 
&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
&lt;value&gt; Master:8088&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
<li><p>配置mapred-site.xml文件，加入如下内容</p>
</li>
<li><pre><code>&lt;configuration&gt;
/*hadoop对map-reduce运行框架一共提供了3种实现，在mapred-site.xml中通过&quot;mapreduce.framework.name&quot;这个属性来设置为&quot;classic&quot;、&quot;yarn&quot;或者&quot;local&quot;*/ 
&lt;property&gt;
&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
&lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
/*MapReduce JobHistory Server地址*/ 
&lt;property&gt;
&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
&lt;value&gt;Master:10020&lt;/value&gt;
&lt;/property&gt;
/*MapReduce JobHistory Server Web UI地址*/ 

&lt;property&gt;
&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
&lt;value&gt;Master:19888&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>###4. 创建namenode和datanode目录，并配置其相应路径</p>
</li>
<li>创建namenode和datanode目录，执行以下命令</li>
<li><pre><code>$ mkdir /hdfs/namenode 
$ mkdir /hdfs/datanode
+ 执行命令后，再次回到目录 /usr/local/hadoop/etc/hadoop，配置hdfs-site.xml 文件，在文件中添加如下内容。
&lt;configuration&gt;
/*配置主节点名和端口号*/ 
&lt;property&gt;
&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
&lt;value&gt;Master:9001&lt;/value&gt;
&lt;/property&gt;
/*配置从节点名和端口号*/ 
&lt;property&gt;
&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
&lt;value&gt;file:/hdfs/namenode&lt;/value&gt;
&lt;/property&gt;
/*配置datanode的数据存储目录*/ 
&lt;property&gt;
&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
&lt;value&gt;file:/hdfs/datanode&lt;/value&gt;
&lt;/property&gt;
/*配置副本数*/ 
&lt;property&gt;
&lt;name&gt;dfs.replication&lt;/name&gt;
&lt;value&gt;3&lt;/value&gt;
&lt;/property&gt;
/*将dfs.webhdfs.enabled属性设置为true，否则就不能使用webhdfs的LISTSTATUS、LISTFILESTATUS等需要列出文件、文件夹状态的命令，因为这些信息都是由namenode保存的*/ 
&lt;property&gt;
&lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>###5.配置Master和Slave文件</p>
<pre><code>1）Master文件负责配置主节点的主机名。例如，主节点名为Master，则需要在Master文件添加以下内容。
        Master /*Master为主节点主机名*/
2）配置Slaves文件添加从节点主机名，这样主节点就可以通过配置文件找到从节点，和从节点进行通信。例如，以Slave1～Slave5为从节点的主机名，就需要在Slaves文件中添加如下信息。
    /Slave*为从节点主机名*/ 
    Slave1 
    Slave2 
    Slave3 
    Slave4 
    Slave5
</code></pre><p>###6. 将Hadoop的所有文件通过pssh分发到各个节点</p>
<pre><code>执行如下命令: ./pssh -h hosts.txt -r /hadoop  /
</code></pre><p>###7. 格式化Namenode（在Hadoop根目录下）</p>
<pre><code>./bin/hadoop namenode -format
</code></pre><p>###8. 启动Hadoop</p>
<pre><code>./sbin/start-all.sh
</code></pre><p>###9. 查看是否配置和启动成功</p>
<pre><code>如果在x86机器上运行，则通过jps命令，查看相应的JVM进
2584 DataNode 
2971 ResourceManager 
3462 Jps 
3179 NodeManager 
2369 NameNode 
2841 SecondaryNameNode
注意，由于在IBM JVM中没有jps命令，所以需要用户按照下面命令逐个查看。
ps-aux|grep *DataNode*     /*查看DataNode进程*/
</code></pre></li>
</ul>
<p>##安装Spark</p>
<p>进入官网下载对应Hadoop版本的Spark程序包（见图2-1），官网地址为<a href="http://spark.apache.org/downloads.html。" target="_blank" rel="external">http://spark.apache.org/downloads.html。</a></p>
<p>以Spark1.0版本为例，介绍Spark的安装。</p>
<ul>
<li><p>下载spark-1.0.0-bin-hadoop2.tgz。</p>
</li>
<li><p>解压tar -xzvf spark-1.0.0-bin-hadoop2.tgz。</p>
</li>
<li><p>配置conf/spark-env.sh文件</p>
<ol>
<li><p>用户可以配置基本的参数，其他更复杂的参数请见官网的配置（Configuration）页面，Spark配置（Configuration）地址为：<a href="http://spark.apache.org/docs/latest/configuration.html。" target="_blank" rel="external">http://spark.apache.org/docs/latest/configuration.html。</a></p>
</li>
<li><p>编辑conf/spark-env.sh文件，加入下面的配置参数</p>
<pre><code>export SCALA_HOME=/path/to/scala-2.10.4 
export SPARK_WORKER_MEMORY=7g
export SPARK_MASTER_IP=172.16.0.140 
export MASTER=spark://172.16.0.140:7077
</code></pre><p> 参数SPARK_WORKER_MEMORY决定在每一个Worker节点上可用的最大内存，增加这个数值可以在内存中缓存更多数据，但是一定要给Slave的操作系统和其他服务预留足够的内存。</p>
<p> 需要配置SPARK_MASTER_IP和MASTER，否则会造成Slave无法注册主机错误。</p>
</li>
</ol>
</li>
<li><p>配置slaves文件。</p>
<pre><code>编辑conf/slaves文件，以5个Worker节点为例，将节点的主机名加入slaves文件中。

Slave1 
Slave2 
Slave3 
Slave4 
Slave5
</code></pre><p>##启动集群</p>
</li>
<li><p>Spark启动与关闭</p>
</li>
<li><pre><code>在Spark根目录启动Spark: ./sbin/start-all.sh
</code></pre></li>
<li><p>关闭Spark</p>
<pre><code>./sbin/stop-all.sh
</code></pre></li>
<li>Hadoop的启动与关闭</li>
<li><pre><code>1）在Hadoop根目录启动Hadoop
    ./sbin/start-all.sh
2）关闭Hadoop
    ./sbin/stop-all.sh
</code></pre></li>
<li><p>检测是否安装成</p>
<p>  1）正常状态下的Master节点如下。</p>
<pre><code>-bash-4.1# jps 
23526 Jps 
2127 Master 
7396 NameNode     
7594 SecondaryNameNode 
7681 ResourceManager
</code></pre><p>  2）利用ssh登录Worker节点</p>
<pre><code>-bash-4.1# ssh slave2 
-bash-4.1# jps 
1405 Worker 
1053 DataNode 
22455 Jps 
31935 NodeManager
</code></pre></li>
</ul>
<p>至此，在Linux集群上安装与配置Spark集群的步骤告一段落。</p>

    </div>
    <footer>
        
  
  <div class="categories">
    <a href="/categories/Spark/">Spark</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/Spark/">Spark</a>
  </div>

		<div class="bdsharebuttonbox">
	<a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a>
	<a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博"></a>
	<a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网"></a>
	<a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
	<a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
	<a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
	<a href="#" class="bds_more" data-cmd="more"></a>
	<a href="#" class="bds_count" data-cmd="count"></a>
</div>
<script>
window._bd_share_config=
{
	"common":{
		"bdSnsKey":{},
		"bdText":"",
		"bdMini":"2",
		"bdMiniList":false,
		"bdPic":"",
		"bdStyle":"0",
		"bdSize":"24"
	},
	"share":{},
	"image":{
		"viewList":["qzone","tsina","tqq","renren","weixin","fbook","twi"],
		"viewText":"分享到：",
		"viewSize":"24"
	},
	"selectShare":{
		"bdContainerClass":null,
		"bdSelectMiniList":["qzone","tsina","tqq","renren","weixin","fbook","twi"]
	}
};
with(document)0[
	(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)
];
</script>    
        <div class="clearfix"></div>
    </footer>
  </div>
</article>

 <nav id="pagination" >
    
    <a href="/2016/07/22/test/" class="alignleft prev" title="test">test</a>
    
    
    <div class="clearfix"></div>
</nav>



	
	<section id="comment">
		<!-- 多说评论框 start -->
		<div class="ds-thread" data-thread-key="2016/07/20/spark安装/" data-title="Centos下Spark的安装" data-url="http://yoursite.com/2016/07/20/spark安装/"></div>
		<!-- 多说评论框 end -->
		<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
		<script type="text/javascript">
		var duoshuoQuery = {short_name:""};
		(function() {
			var ds = document.createElement('script');
			ds.type = 'text/javascript';ds.async = true;
			ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
			ds.charset = 'UTF-8';
			(document.getElementsByTagName('head')[0] 
			 || document.getElementsByTagName('body')[0]).appendChild(ds);
		})();
		</script>
		<!-- 多说公共JS代码 end -->
	</section>
	
</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:yoursite.com">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Categories</h3>
  <ul class="entry">
  
    <li><a href="/categories/Spark/">Spark</a><small>2</small></li>
  
    <li><a href="/categories/test/">test</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">Tag Cloud</h3>
  <div class="entry">
    <a href="/tags/Spark/" style="font-size: 20px;">Spark</a> <a href="/tags/test/" style="font-size: 10px;">test</a>
  </div>
</div>


  <iframe width="100%" height="140" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=2&ptype=1&speed=0&skin=1&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=1923610190&verifier=6af5ad6a&colors=fafafa,fafafa,666666,0082cb,ecfbfd&dpc=1"></iframe>

  <div class="widget tag">
<h3 class="title">友情链接</h3>
<ul class="entry">
<li><a href="http://opiece.me" title="Chillax's Blog" target="_blank">Chillax</a></li>
</ul>
</div>
</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer"><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<div class="social-font clearfix">
		
		
		
		
		
		
	</div>
		<p class="copyright">Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/huangjunhui/concise" target="_blank" title="Concise">Concise</a> © 2016 
		
		<a href="http://yoursite.com/about" target="_blank" title="Gason">Gason</a>
		
		</p>
</div>
</footer>
  <script src="//libs.baidu.com/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/counter.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

<div id="totop" style="position:fixed;bottom:100px;right:10px;cursor: pointer;">
<a title="返回顶部"><img src="/imgs/scrollup.png"/></a>
</div>
<script src="/js/totop.js"></script>
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>


