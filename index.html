<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>wingOFeagle之技术博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="ok">
<meta property="og:type" content="website">
<meta property="og:title" content="wingOFeagle之技术博客">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="wingOFeagle之技术博客">
<meta property="og:description" content="ok">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="wingOFeagle之技术博客">
<meta name="twitter:description" content="ok">
  
    <link rel="alternate" href="/atom.xml" title="wingOFeagle之技术博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">wingOFeagle之技术博客</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">一步步，一点点...</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Spark学习小结" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/22/Spark学习小结/" class="article-date">
  <time datetime="2016-07-22T10:02:21.000Z" itemprop="datePublished">2016-07-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/07/22/Spark学习小结/">Spark学习小结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>#什么是spark </p>
<ul>
<li><strong>Spark</strong>是一种基于内存的分布式处理框架。其在hadoop MR基础上进行扩展，扩展后的spark不仅仅支持map与reduce的操作，而且支持包括map的Transform操作与包括reduce的Action操作。相较于受限于磁盘IO瓶颈的hadoop，基于内存的spark在性能的提升上有了较大的进步，尤其是以重复使用数据为主要特点的迭代运算（ML也上使用迭代运算）<ul>
<li>官方主页：<a href="http://spark.apache.org/docs/latest/" target="_blank" rel="external">http://spark.apache.org/docs/latest/</a></li>
</ul>
</li>
<li><strong>spark 运行模式</strong><ul>
<li>本地模式</li>
<li>Standalone模式</li>
<li>Mesoes模式</li>
<li>yarn模式</li>
</ul>
</li>
<li><strong>spark 配置</strong><ul>
<li><a href="http://spark.apache.org/docs/latest/configuration.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/configuration.html</a></li>
</ul>
</li>
<li><p><strong>spark常用名词</strong></p>
<ul>
<li><strong>master &amp; worker</strong>，整个集群分为 Master 节点和 Worker 节点，相当于 Hadoop 的 Master 和 Slave 节点</li>
<li><strong>Master</strong> 节点上常驻 Master 守护进程，负责管理全部的 Worker 节点</li>
<li><strong>Worker</strong> 节点上常驻 Worker 守护进程，负责与 Master 节点通信并管理 executors</li>
<li><strong>driver application</strong>，即要运行的spark程序</li>
<li><strong>executor</strong>，在一个Worker Node上为应用启动的工作进程，在进程中赋值任务的运行，并且负责将数据存放在内存或磁盘上，必须注意的是，每个应用在一个Worker Node上只会有一个Executor，在Executor内部通过多线程的方式并发处理应用的任务</li>
<li><strong>job</strong>，和Spark的action相对应，每一个action例如count、saveAsTextFile等都会对应一个job实例，该job实例包含多任务的并行计算<br>cluster manager，集群资源的管理外部服务，在spark上现在有standalone、yarn、mesos等三种集群资源管理器，spark自带的standalone模式能够满足大部分的spark计算环境对集群资源管理的需求，基本上只有在集群中运行多套计算框架的时候才考虑yarn和mesos</li>
<li><strong>task</strong></li>
<li><a href="&quot;/img/RDD1.png&quot;">RDD1</a></li>
<li><strong>RDD</strong>，即resilient distributed dataset，弹性分布式数据集。它是一个只读，可分区的分布式数据集，这些数据集大部分分布在内存中（当然可以控制存储级别：内存、磁盘等）。RDD的初始化通过sparkcontext进行加载，加载的来源既可以是以hdfs为代表的分布式存储系统也可以是普通的文件。针对RDD的数据集，spark提供了两类操作，transform（返回值还是一个RDD）与action（返回值不是一个RDD）<ul>
<li>Transformations (如：map, filter, groupBy, join等)，Transformations操作是Lazy的，也就是说从一个RDD转换生成另一个RDD的操作不是马上执行，Spark在遇到Transformations操作时只会记录需要这样的操作，并不会去执行，需要等到有Actions操作的时候才会真正启动计算过程进行计算</li>
<li>Actions)（如：count, collect, save等)，Actions操作会返回结果或把RDD数据写到存储系统中。Actions是触发Spark启动计算的动因。</li>
<li>如下图所示，RDD的存储结构。事实上，每个RDD的数据都以Block的形式存储于多台机器上，其中每个Executor会启动一个BlockManagerSlave，并管理一部分Block；而Block的元数据由Driver节点的BlockManagerMaster保存。BlockManagerSlave生成Block后向BlockManagerMaster注册该Block，BlockManagerMaster管理RDD与Block的关系，当RDD不再需要存储的时候，将向BlockManagerSlave发送指令删除相应的Block。<br><a href="&quot;/img/RDD2.png&quot;">RDD2</a></li>
<li>Reference：</li>
<li><pre><code>RDD 原理： http://blog.csdn.net/stark_summer/article/details/47174733；
RDD: http://www.aboutyun.com/forum.php?mod=viewthread&amp;tid=7214&amp;page=1
Spark：http://tech.uc.cn/?p=2116
spark名词解释：http://blog.csdn.net/stark_summer/article/details/42833609
</code></pre></li>
</ul>
</li>
<li><strong>DAG</strong>：Direct Acycle graph，有向无环图，反映RDD之间的依赖关系</li>
<li><strong>narrow dependency</strong>，子RDD 依赖于父RDD 固定的data partition</li>
<li><p><strong>wide/shuffle dependency</strong>，子RDD 依赖于父RDD 所有的data partition</p>
<h1 id="spark的应用场景"><a href="#spark的应用场景" class="headerlink" title="spark的应用场景"></a>spark的应用场景</h1><p>spark可以用于实时计算（需要较高的内存要求，更加适合于迭代或者重复运算）、ML、关系数据查询、图形处理<br><a href="&quot;/img/spark应用.png&quot;">spark应用</a></p>
<pre><code>.
</code></pre><h1 id="spark的容错机制"><a href="#spark的容错机制" class="headerlink" title="spark的容错机制"></a>spark的容错机制</h1></li>
</ul>
</li>
<li>基于RDD 的分布式spark容错机制<strong>Lineage</strong>，其具有两种方式分别是数据检查点和记录数据的更新<ul>
<li>数据检查点是在某个stage将结果存储下来，当失败的节点恢复后节点从文件中读取数据进行加载恢复业务，优点是能够较快的恢复数据，缺点是会生成大量的数据文件<ul>
<li>Reference：<a href="http://www.cnblogs.com/gaoxing/p/4847119.html" target="_blank" rel="external">http://www.cnblogs.com/gaoxing/p/4847119.html</a></li>
</ul>
</li>
<li>记录数据的更新，它是把RDD生成的依赖关系记录下来，当数据丢失时根据依赖关系重新生成数据。当前RDD只支持粗粒度转换（细粒度的成本更新成本太高），即只记录单个块上执行的单个操作，然后将创建RDD的一系列变换序列（每个RDD都包含了他是如何由其他RDD变换过来的以及如何重建某一块数据的信息。因此RDD的容错机制又称“血统(Lineage)”容错）记录下来，以便恢复丢失的分区。其优点是对于窄依赖（narrow dependency）可以很快的进行数据还原，但对于复杂且Lineage较长的宽依赖则耗时较长而且往往占用较多的资源，因此在处理Lineage较长的宽依赖时往往采用“数据检查点+记录数据更新”的方式。<ul>
<li>Reference：<a href="http://www.jianshu.com/p/99ebcc7c92d3" target="_blank" rel="external">http://www.jianshu.com/p/99ebcc7c92d3</a><h1 id="spark-的资源管理与任务调度"><a href="#spark-的资源管理与任务调度" class="headerlink" title="spark 的资源管理与任务调度"></a>spark 的资源管理与任务调度</h1></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>##资源管理</p>
<ul>
<li>spark的资源管理一般由cluster manager进行</li>
<li>不同application间，支持资源动态调整，设定时间内无活动的job所占用的资源会被回收，需要资源的job spark会以1-2-4-8以此类推的形式逐步分配资源</li>
<li>同一个application内，不同的线程可以组成不同的池（pool），池可以设置不同的优先级来将资源优先分配给更重要job。缺省配置下，不同的池采用Roundrobin进行资源调度，同一个池内job采用FIFO进行调度</li>
<li><p>Reference：官网资源调度说明，<a href="http://spark.apache.org/docs/latest/job-scheduling.html#graceful-decommission-of-executors" target="_blank" rel="external">http://spark.apache.org/docs/latest/job-scheduling.html#graceful-decommission-of-executors</a></p>
<h2 id="任务调度"><a href="#任务调度" class="headerlink" title="任务调度"></a>任务调度</h2><p><a href="&quot;/img/spark 调度1.png&quot;">spark 调度1</a><br><a href="&quot;/img/spark 调度2.png&quot;">spark 调度2</a><br><a href="&quot;/img/spark 调度3.png&quot;">spark 调度3</a></p>
<p> 在用户创建 SparkContext 对象时，Spark会在内部创建 DAGScheduler 对象，并根据用户的部署情况，绑定不同的 TaskSechduler ，并启动DAGScheduler。基于生产-消费模型的DAGSchedual启动后调用 processEvent来处理block queue 中的event（event类型：JobSubmitted/CompletionEvent/ExecutorLost/TaskFailed/StopDAGScheduler），其具体的流程如下：</p>
</li>
</ul>
<ol>
<li>客户端启动Driver（spark作业的master）时同时启动JobGenerator，其根据Dstream的关系生成逻辑RDD，并创建Jobset；</li>
<li>用户提交的Job时（JobSchedual负责调度Jobset，即Job集合），对应的action操作触发sparkcontext调用RunJob函数，该函数执行DAGSchedualer的RunJob函数，而该函数把job封装成JobSubmitted 事件后放入block queue，等待执行；</li>
<li><p>DAGSchedual的daemon线程调用processEvent函数 从 block queue中取出 JobSubmitted事件后，根据job划分成不同的stage，然后根据每个stage产生task；</p>
<pre><code>1） 根据stage所依赖的 RDD 的partition的分布，会产生出与partition数量相等的task，这些task根据partition的locality进行分布；
2） 对于 finalStage 或是mapStage 会产生不同的task；
3） 所有的task会封装到 TaskSet 类内进行处理；
</code></pre></li>
<li>这些TaskSet类由TaskSetManager来进行管理（包括task的运行状态，locality处理，比如需要delay scheduling）；</li>
<li>那么，TaskSetManager是怎么管理这些task的呢？原来它会调用其内的resourceOffer方法，该方法实现task与底下资源的交互，这个资源交互的协调人是TaskScheduler；</li>
<li>同时，TaskScheduler对接不同的SchedulerBackend的实现(比如mesos，yarn，standalone)，如此来对接不同的资源管理系统 ；</li>
<li>而对资源管理系统来说，他们要负责的是进程，是worker上起几个executor进程，每个进程分配多少资源。所以这两层很清楚， spark本身计算框架内管理线程级别的task ，每个stage都有一个TaskSet，本身是个小DAG，可以丢到全局可用的资源池里跑；spark下半身的 双层资源管理部分掌控的是进程级别的executor ，不关心task怎么摆放，也不关心task运行状态，这是TaskSetManager管理的事情， 两者的协调者就是TaskScheduler及其内的SchedulerBackend实现（即将线程级别的task调度到进程级别的executor上）。</li>
</ol>
<ul>
<li>Reference：<ul>
<li>spark streaming 原理：<a href="http://blog.csdn.net/stark_summer/article/details/47252619" target="_blank" rel="external">http://blog.csdn.net/stark_summer/article/details/47252619</a></li>
<li>spark 任务调度：<a href="http://www.aboutyun.com/thread-8548-1-1.html" target="_blank" rel="external">http://www.aboutyun.com/thread-8548-1-1.html</a></li>
<li>spark任务调度：<a href="http://www.tuicool.com/articles/IZr6bi" target="_blank" rel="external">http://www.tuicool.com/articles/IZr6bi</a></li>
<li>spark总况：<a href="http://blog.csdn.net/stark_summer/article/details/45917603" target="_blank" rel="external">http://blog.csdn.net/stark_summer/article/details/45917603</a><h1 id="spark扩容"><a href="#spark扩容" class="headerlink" title="spark扩容"></a>spark扩容</h1></li>
</ul>
</li>
<li><strong>动态扩容</strong>：<a href="http://blog.csdn.net/rosen_luo/article/details/46738165" target="_blank" rel="external">http://blog.csdn.net/rosen_luo/article/details/46738165</a></li>
<li><strong>非动态扩容</strong>：<a href="http://www.linuxidc.com/Linux/2015-08/120937.htm" target="_blank" rel="external">http://www.linuxidc.com/Linux/2015-08/120937.htm</a><h1 id="spark的组件"><a href="#spark的组件" class="headerlink" title="spark的组件"></a>spark的组件</h1></li>
<li><strong>akka</strong>，消息队列系统，在spark中作为消息系统为master,worker,driver等通信 <ul>
<li>Reference<ul>
<li>akka：<a href="http://zuohongbin.com/2014/12/16/Akka-Tutorial-with-Code-Conncurrency-and-Fault-Tolerance/" target="_blank" rel="external">http://zuohongbin.com/2014/12/16/Akka-Tutorial-with-Code-Conncurrency-and-Fault-Tolerance/</a></li>
<li>spark总况：<a href="http://blog.csdn.net/stark_summer/article/details/45917603" target="_blank" rel="external">http://blog.csdn.net/stark_summer/article/details/45917603</a></li>
</ul>
</li>
</ul>
</li>
<li><strong>tachyon</strong>，分布式内存文件系统，在spark中用来存储RDD<ul>
<li>Reference：<ul>
<li>tachyon：<a href="http://www.csdn.net/article/2015-06-25/2825056" target="_blank" rel="external">http://www.csdn.net/article/2015-06-25/2825056</a></li>
<li>spark总况：<a href="http://blog.csdn.net/stark_summer/article/details/45917603" target="_blank" rel="external">http://blog.csdn.net/stark_summer/article/details/45917603</a></li>
</ul>
</li>
</ul>
</li>
<li><strong>netty</strong>，一个基于事件驱动的网络通信框架，目前在spark中主要作为spark shuffle处理后 从各个解决拉取shuffle数据（shuffle dependency阶段使用）<ul>
<li>Reference：<ul>
<li>spark总况：<a href="http://blog.csdn.net/stark_summer/article/details/45917603" target="_blank" rel="external">http://blog.csdn.net/stark_summer/article/details/45917603</a></li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/22/Spark学习小结/" data-id="ciqxkwbel000056j6k0pksez9" class="article-share-link">Partager</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-test" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/22/test/" class="article-date">
  <time datetime="2016-07-22T09:03:52.000Z" itemprop="datePublished">2016-07-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/test/">test</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/07/22/test/">test</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a href="http://baidu.com" title="百度" target="_blank" rel="external">百度</a></p>
<p><img src="/img/1.jpg" alt="图片" title="图片"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/22/test/" data-id="ciqxkwbev000856j6g3hg3ta2" class="article-share-link">Partager</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/test/">test</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-spark安装" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/20/spark安装/" class="article-date">
  <time datetime="2016-07-20T12:48:32.000Z" itemprop="datePublished">2016-07-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Spark/">Spark</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/07/20/spark安装/">Centos下Spark的安装</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>#Centos下Spark的安装与配置</p>
<p>##安装JDK</p>
<p>安装JDK大致分为下面4个步骤<br>用户可以在Oracle JDK的官网下载相应版本的JDK，本例以JDK 1.6为例，官网地址为<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="external">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a></p>
<ul>
<li><p>下载后，在解压出的JDK的目录下执行bin文件</p>
<pre><code>./jdk-6u38-ea-bin-b04-linux-amd64-31_oct_2012.bin
</code></pre></li>
<li><p>配置环境变量，在/etc/profile增加以下代码</p>
<pre><code>JAVA_HOME=/home/chengxu/jdk1.6.0_38 
PATH=$JAVA_HOME/bin:$PATH 
CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/jre/lib/dt.jar:$JAVA_HOME/jre/lib/tools.jar 
export JAVA_HOME PATH CLASSPATH
</code></pre></li>
<li><p>使profile文件更新生效</p>
</li>
<li><pre><code>./etc/profile
</code></pre><p>##安装Scala<br>Scala官网提供各个版本的Scala，用户需要根据Spark官方规定的Scala版本进行下载和安装。Scala官网地址为<a href="http://www.scala-lang.org/.以Scala-2.10为例进行介绍" target="_blank" rel="external">http://www.scala-lang.org/.以Scala-2.10为例进行介绍</a>.</p>
</li>
<li><p>下载scala-2.10.4.tgz</p>
</li>
<li>在目录下解压：tar -xzvf scala-2.10.4.tgz</li>
<li>配置环境变量，在/etc/profile中添加下面的内容</li>
<li><pre><code>export SCALA_HOME=/home/chengxu/scala-2.10.4/scala-2.10.4 
export PATH=${SCALA_HOME}/bin:$PATH
</code></pre></li>
<li>使profile文件更新生效</li>
<li><pre><code>./etc/profile
</code></pre><p>##配置SSH免密码登录</p>
<blockquote>
<p> 在集群管理和配置中有很多工具可以使用。例如，可以采用pssh等Linux工具在集群中分发与复制文件，用户也可以自己书写Shell、Python的脚本分发包。Spark的Master节点向Worker节点发命令需要通过ssh进行发送，用户不希望Master每发送一次命令就输入一次密码，因此需要实现Master无密码登录到所有Worker。<br>Master作为客户端，要实现无密码公钥认证，连接到服务端Worker。需要在Master上生成一个密钥对，包括一个公钥和一个私钥，然后将公钥复制到Worker上。当Master通过ssh连接Woker时，Worker就会生成一个随机数并用Master的公钥对随机数进行加密，发送给Worker。Master收到加密数之后再用私钥进行解密，并将解密数回传给Worker，Worker确认解密数无误之后，允许Master进行连接。这就是一个公钥认证过程，其间不需要用户手工输入密码，主要过程是将Master节点公钥复制到Worker节点上。<br>下面介绍如何配置Master与Worker之间的SSH免密码登录。</p>
</blockquote>
</li>
<li><p>在Master节点上，执行以下命令</p>
</li>
<li><pre><code>ssh-keygen -t rsa
</code></pre></li>
<li>打印日志执行以下命令</li>
<li><pre><code>Generating public/private rsa key pair. 
Enter file in which to save the key (/root/.ssh/id_rsa): 
/*回车，设置默认路径*/ 
Enter passphrase (empty for no passphrase): 
/*回车，设置空密码*/ 
Enter same passphrase again: 
Your identification has been saved in /root/.ssh/id_rsa. 
Your public key has been saved in /root/.ssh/id_rsa.pub.
如果是root用户，则在/root/.ssh/目录下生成一个私钥id_rsa和一个公钥id_rsa.pub。
 把Master上的id_rsa.pub文件追加到Worker的authorized_keys内，以172.20.14.144 （Worker）节点为例
</code></pre></li>
<li><p>复制Master的id_rsa.pub文件</p>
</li>
<li><pre><code>scp id_rsa.pub root@172.20.14.144:/home
</code></pre></li>
<li>可使用pssh对全部节点分发</li>
<li><pre><code>登录172.20.14.144 (Worker节点)，执行以下命令。
cat /home/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys 
/*可使用pssh对全部节点分发*/
</code></pre>其他的Worker执行同样的操作。</li>
</ul>
<blockquote>
<p>注意：配置完毕，如果Master仍然不能访问Worker，可以修改Worker的authorized_keys文件的权限，命令为chmod 600 authorized_keys。</p>
</blockquote>
<p>##安装Hadoop</p>
<p>下面讲解Hadoop的安装过程和步骤。</p>
<p>###1.下载hadoop-2.2.0</p>
<ul>
<li>选取一个Hadoop镜像网址，下载Hadoop（官网地址为<a href="http://hadoop.apache.org/）" target="_blank" rel="external">http://hadoop.apache.org/）</a></li>
<li><pre><code>$ wget http://www.trieuvan.com/apache/hadoop/common/ hadoop-2.2.0/hadoop-2.2.0.tar.gz
</code></pre></li>
<li>解压tar包</li>
<li><pre><code>$ sudo tar-vxzf hadoop-2.2.0.tar.gz -C /usr/local 
$ cd /usr/local 
$ sudo mv hadoop-2.2.0 hadoop 
$ sudo chown -R hduser:hadoop hadoop
</code></pre><p>###2. 配置Hadoop环境变量</p>
<ul>
<li>编辑profile文件</li>
<li><pre><code>vi /etc/profile
</code></pre></li>
<li><p>在profile文件中增加以下内容</p>
</li>
<li><pre><code>export JAVA_HOME=/usr/lib/jvm/jdk/ 
export HADOOP_INSTALL=/usr/local/hadoop 
export PATH=$PATH:$HADOOP_INSTALL/bin 
export PATH=$PATH:$HADOOP_INSTALL/sbin 
export HADOOP_MAPRED_HOME=$HADOOP_INSTALL 
export HADOOP_COMMON_HOME=$HADOOP_INSTALL 
export HADOOP_HDFS_HOME=$HADOOP_INSTALL 
export YARN_HOME=$HADOOP_INSTALL
</code></pre>通过如上配置就可以让系统找到JDK和Hadoop的安装路径。</li>
</ul>
</li>
</ul>
<p>###3. 编辑配置文件</p>
<ul>
<li><p>进入Hadoop所在目录/usr/local/hadoop/etc/hadoop</p>
</li>
<li><p>配置hadoop-env.sh文件</p>
</li>
<li><pre><code>export JAVA_HOME=/usr/lib/jvm/jdk/
</code></pre></li>
<li>配置core-site.xml文件（主配置文件）</li>
<li><pre><code>&lt;configuration&gt;
/*这里的值指的是默认的HDFS路径*/ 
&lt;property&gt;
&lt;name&gt;fs.defaultFS&lt;/name&gt;
&lt;value&gt;hdfs://Master:9000&lt;/value&gt;
&lt;/property&gt;
/*缓冲区大小:io.file.buffer.size默认是4KB*/ 
&lt;property&gt;
&lt;name&gt;io.file.buffer.size&lt;/name&gt;
&lt;value&gt;131072&lt;/value&gt;
&lt;/property&gt;
/*临时文件夹路径*/ 
&lt;property&gt;
&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
&lt;value&gt;file:/home//tmp&lt;/value&gt;
&lt;description&gt;Abase for other  
temporary directories.       &lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;hadoop.proxyuser.hduser.hosts&lt;/name&gt;
&lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;hadoop.proxyuser.hduser.groups&lt;/name&gt;
&lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
<li>配置yarn-site.xml文件（资源调度文件）</li>
<li><pre><code>&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
&lt;/property&gt;
/*resourcemanager的地址*/ 
&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
&lt;value&gt;Master:8032&lt;/value&gt;
&lt;/property&gt;
/*调度器的端口*/ 
&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
&lt;value&gt; Master1:8030&lt;/value&gt;
&lt;/property&gt;
/*resource-tracker端口*/ 
&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
&lt;value&gt; Master:8031&lt;/value&gt;
&lt;/property&gt;
/*resourcemanager管理器端口*/ 
&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
&lt;value&gt; Master:8033&lt;/value&gt;
&lt;/property&gt;
/* ResourceManager 的 Web 端口，监控 job 的资源调度*/ 
&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
&lt;value&gt; Master:8088&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
<li><p>配置mapred-site.xml文件，加入如下内容</p>
</li>
<li><pre><code>&lt;configuration&gt;
/*hadoop对map-reduce运行框架一共提供了3种实现，在mapred-site.xml中通过&quot;mapreduce.framework.name&quot;这个属性来设置为&quot;classic&quot;、&quot;yarn&quot;或者&quot;local&quot;*/ 
&lt;property&gt;
&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
&lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
/*MapReduce JobHistory Server地址*/ 
&lt;property&gt;
&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
&lt;value&gt;Master:10020&lt;/value&gt;
&lt;/property&gt;
/*MapReduce JobHistory Server Web UI地址*/ 

&lt;property&gt;
&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
&lt;value&gt;Master:19888&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>###4. 创建namenode和datanode目录，并配置其相应路径</p>
</li>
<li>创建namenode和datanode目录，执行以下命令</li>
<li><pre><code>$ mkdir /hdfs/namenode 
$ mkdir /hdfs/datanode
+ 执行命令后，再次回到目录 /usr/local/hadoop/etc/hadoop，配置hdfs-site.xml 文件，在文件中添加如下内容。
&lt;configuration&gt;
/*配置主节点名和端口号*/ 
&lt;property&gt;
&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
&lt;value&gt;Master:9001&lt;/value&gt;
&lt;/property&gt;
/*配置从节点名和端口号*/ 
&lt;property&gt;
&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
&lt;value&gt;file:/hdfs/namenode&lt;/value&gt;
&lt;/property&gt;
/*配置datanode的数据存储目录*/ 
&lt;property&gt;
&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
&lt;value&gt;file:/hdfs/datanode&lt;/value&gt;
&lt;/property&gt;
/*配置副本数*/ 
&lt;property&gt;
&lt;name&gt;dfs.replication&lt;/name&gt;
&lt;value&gt;3&lt;/value&gt;
&lt;/property&gt;
/*将dfs.webhdfs.enabled属性设置为true，否则就不能使用webhdfs的LISTSTATUS、LISTFILESTATUS等需要列出文件、文件夹状态的命令，因为这些信息都是由namenode保存的*/ 
&lt;property&gt;
&lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>###5.配置Master和Slave文件</p>
<pre><code>1）Master文件负责配置主节点的主机名。例如，主节点名为Master，则需要在Master文件添加以下内容。
        Master /*Master为主节点主机名*/
2）配置Slaves文件添加从节点主机名，这样主节点就可以通过配置文件找到从节点，和从节点进行通信。例如，以Slave1～Slave5为从节点的主机名，就需要在Slaves文件中添加如下信息。
    /Slave*为从节点主机名*/ 
    Slave1 
    Slave2 
    Slave3 
    Slave4 
    Slave5
</code></pre><p>###6. 将Hadoop的所有文件通过pssh分发到各个节点</p>
<pre><code>执行如下命令: ./pssh -h hosts.txt -r /hadoop  /
</code></pre><p>###7. 格式化Namenode（在Hadoop根目录下）</p>
<pre><code>./bin/hadoop namenode -format
</code></pre><p>###8. 启动Hadoop</p>
<pre><code>./sbin/start-all.sh
</code></pre><p>###9. 查看是否配置和启动成功</p>
<pre><code>如果在x86机器上运行，则通过jps命令，查看相应的JVM进
2584 DataNode 
2971 ResourceManager 
3462 Jps 
3179 NodeManager 
2369 NameNode 
2841 SecondaryNameNode
注意，由于在IBM JVM中没有jps命令，所以需要用户按照下面命令逐个查看。
ps-aux|grep *DataNode*     /*查看DataNode进程*/
</code></pre></li>
</ul>
<p>##安装Spark</p>
<p>进入官网下载对应Hadoop版本的Spark程序包（见图2-1），官网地址为<a href="http://spark.apache.org/downloads.html。" target="_blank" rel="external">http://spark.apache.org/downloads.html。</a></p>
<p>以Spark1.0版本为例，介绍Spark的安装。</p>
<ul>
<li><p>下载spark-1.0.0-bin-hadoop2.tgz。</p>
</li>
<li><p>解压tar -xzvf spark-1.0.0-bin-hadoop2.tgz。</p>
</li>
<li><p>配置conf/spark-env.sh文件</p>
<ol>
<li><p>用户可以配置基本的参数，其他更复杂的参数请见官网的配置（Configuration）页面，Spark配置（Configuration）地址为：<a href="http://spark.apache.org/docs/latest/configuration.html。" target="_blank" rel="external">http://spark.apache.org/docs/latest/configuration.html。</a></p>
</li>
<li><p>编辑conf/spark-env.sh文件，加入下面的配置参数</p>
<pre><code>export SCALA_HOME=/path/to/scala-2.10.4 
export SPARK_WORKER_MEMORY=7g
export SPARK_MASTER_IP=172.16.0.140 
export MASTER=spark://172.16.0.140:7077
</code></pre><p> 参数SPARK_WORKER_MEMORY决定在每一个Worker节点上可用的最大内存，增加这个数值可以在内存中缓存更多数据，但是一定要给Slave的操作系统和其他服务预留足够的内存。</p>
<p> 需要配置SPARK_MASTER_IP和MASTER，否则会造成Slave无法注册主机错误。</p>
</li>
</ol>
</li>
<li><p>配置slaves文件。</p>
<pre><code>编辑conf/slaves文件，以5个Worker节点为例，将节点的主机名加入slaves文件中。

Slave1 
Slave2 
Slave3 
Slave4 
Slave5
</code></pre><p>##启动集群</p>
</li>
<li><p>Spark启动与关闭</p>
</li>
<li><pre><code>在Spark根目录启动Spark: ./sbin/start-all.sh
</code></pre></li>
<li><p>关闭Spark</p>
<pre><code>./sbin/stop-all.sh
</code></pre></li>
<li>Hadoop的启动与关闭</li>
<li><pre><code>1）在Hadoop根目录启动Hadoop
    ./sbin/start-all.sh
2）关闭Hadoop
    ./sbin/stop-all.sh
</code></pre></li>
<li><p>检测是否安装成</p>
<p>  1）正常状态下的Master节点如下。</p>
<pre><code>-bash-4.1# jps 
23526 Jps 
2127 Master 
7396 NameNode     
7594 SecondaryNameNode 
7681 ResourceManager
</code></pre><p>  2）利用ssh登录Worker节点</p>
<pre><code>-bash-4.1# ssh slave2 
-bash-4.1# jps 
1405 Worker 
1053 DataNode 
22455 Jps 
31935 NodeManager
</code></pre></li>
</ul>
<p>至此，在Linux集群上安装与配置Spark集群的步骤告一段落。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/20/spark安装/" data-id="ciqxkwbet000556j64gzeu7de" class="article-share-link">Partager</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>

    </footer>
  </div>
  
</article>


  

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Catégories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/">Spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/test/">test</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Mot-clés</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/test/">test</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Nuage de mot-clés</h3>
    <div class="widget tagcloud">
      <a href="/tags/Spark/" style="font-size: 20px;">Spark</a> <a href="/tags/test/" style="font-size: 10px;">test</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/07/22/Spark学习小结/">Spark学习小结</a>
          </li>
        
          <li>
            <a href="/2016/07/22/test/">test</a>
          </li>
        
          <li>
            <a href="/2016/07/20/spark安装/">Centos下Spark的安装</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Gason<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>